# -*- coding: utf-8 -*-
"""NLP assignment - functions only.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AKdF271oNzZ9Qk48tpxDU9fMBTgpv67y

# Libraries & Paths
"""

pip install pattern

#import all the libraries needed
import nltk
import re
nltk.download("punkt")
nltk.download('brown')
from nltk.corpus import brown
from nltk.util import ngrams
from nltk import edit_distance as ED
import heapq
from collections import Counter
from pathlib import Path
import time
import pandas as pd
import itertools
from pattern.en import conjugate, lemma, lexeme, PRESENT, SG

# paths to files
aml_path = '/content/drive/MyDrive/Colab Notebooks/Natural Language Processing/assignment/corpus_AML_textbook.txt'
dl_path = '/content/drive/MyDrive/Colab Notebooks/Natural Language Processing/assignment/corpus_DL_textbook.txt'
noisy_channel_path = "/content/drive/MyDrive/Colab Notebooks/Natural Language Processing/assignment/channel.xlsx"

"""# Text preprocessing
- exclude unwanted texts
- build unigram and bigram corpora

## Text cleaning
"""

# regular expression pattern

# website URL
website_pattern = r'(http|ftp|https+:\/\/)?([\w_-]+(?:(?:\.[\w_-]+)+))([\w.,@?^=%&:\/~+#-]*[\w@?^=%&\/~+#-])?'

# email address
email_pattern = r'[\w\.-]+@[\w\.-]+'

# in-text citation
author = r"(?:[A-Z][A-Za-z'`-]+)"
etal = r"(?:et al\.?)"
additional = f"(?:,? (?:(?:and |& )?{author}|{etal}))"
year_num = "(?:19|20)[0-9][0-9]"
page_num = "(?:, p\.? [0-9]+)?"
year = fr"(?:, *{year_num}{page_num}| *\({year_num}{page_num}\))"
citation_pattern = fr'\b(?!(?:Although|Also)\b){author}{additional}*{year}'
citation_pattern_1 = fr'\b(?!(?:Although|Also|Similarly)\b){author}{additional}*{year}'
citation_pattern_2 = '\(([^()\d]*\d[^()]*)' # less formally written in-text citation

# abbreviation within parenthesis
abbrev_pattern = r'([A-Z]*\s?[A-Z]+[^a-z0-9\W])'

"""## Unigram corpus"""

# function for building unigram corpus without duplicate

def corpus(path, corpus_tokens):
    
    with open(path, 'r', encoding='utf8') as fileinput:
        for line in fileinput:
            line = line.lower()    #convert string into lowercases
            output = re.findall(email_pattern, line)    #capture email address in the string
            output2 = ["".join(x) for x in re.findall(website_pattern, line)]    #capture website in the string
            output3 = re.findall(citation_pattern, line) #capture formal in-text citation
            output4 = re.findall(citation_pattern_2, line) #capture improperly written in-text citation
            
            citation_output = list(set(output3 + output4)) #combine and remove duplication, if any
            
            words = nltk.word_tokenize(line)    #tokenize the string

            for word in words:
                if word.isalnum() and not word.isdigit() and len(word)>1 and word not in output and word not in output2 and word not in citation_output and word not in corpus_tokens:
                    corpus_tokens.append(word)
    fileinput.close()   
    
    return corpus_tokens

# build unigram corpus with aml and dl textbooks without duplicate
unigram_corpus = corpus(aml_path, corpus_tokens=[])
unigram_corpus = corpus(dl_path, unigram_corpus)

# include brown corpus to augment unigram corpus
brown_words = set(brown.words())

#brown_wordlist = []
for word in brown_words:
  brown_wordlist.append(word.lower())
len(brown_wordlist)

for word in brown_wordlist:
  if word not in unigram_corpus:
    unigram_corpus.append(word)

print("number of unique words in unigram_corpus: ", len(unigram_corpus))

"""## Bigram corpus"""

# function for building unigram corpus with duplicates

def corpus2(path, corpus_tokens):
    
    with open(path, 'r', encoding='utf8') as fileinput:
        for line in fileinput:
            line = line.lower()    #convert string into lowercases
            output = re.findall(email_pattern, line)    #capture email address in the string
            output2 = ["".join(x) for x in re.findall(website_pattern, line)]    #capture website in the string
            output3 = re.findall(citation_pattern, line) #capture formal in-text citation
            output4 = re.findall(citation_pattern_2, line) #capture improperly written in-text citation
            
            citation_output = list(set(output3 + output4)) #combine and remove duplication, if any
            
            words = nltk.word_tokenize(line)    #tokenize the string

            for word in words:
                if word == 'a':
                    corpus_tokens.append(word)
                elif word.isalnum() and not word.isdigit() and len(word)>1 and word not in output and word not in output2 and word not in citation_output:
                    corpus_tokens.append(word)
    fileinput.close()   
    
    return corpus_tokens

# build unigram corpus with aml and dl textbooks with duplicates
corpus_tokens_dup = corpus2(aml_path, corpus_tokens=[])
corpus_tokens_dup = corpus2(dl_path, corpus_tokens_dup)

#number of unique words in our unigram corpus
V = len(list(set(corpus_tokens_dup)))

# build bigram corpus
bigram_corpus = list(ngrams(corpus_tokens_dup,2))
bigram_count = Counter(bigram_corpus)

corpus_tokens_aml = corpus2(aml_path, corpus_tokens=[])
corpus_tokens_dl = corpus2(dl_path, corpus_tokens=[])
print("number of words in AML textbook: ", len(corpus_tokens_aml))
print("number of words in DL textbook: ", len(corpus_tokens_dl))

total_words = int(len(corpus_tokens_aml)) + int(len(corpus_tokens_dl))
print("total number of words: ", total_words)

uniq_tokens_aml = corpus(aml_path, corpus_tokens=[])
uniq_tokens_dl = corpus(dl_path, corpus_tokens=[])
print("number of unique words in AML textbook: ", len(uniq_tokens_aml))
print("number of unique words in DL textbook: ", len(uniq_tokens_dl))

print("total number of unique words: ", V)

"""# Non-word error

## Error detection
"""

def error_detection(input_text, corpus_tokens):

    error_list = []

    #perform regex operation on the entire input text, instead of on the word level
    citation_output = re.findall(citation_pattern_1, input_text)#must process before lower() since the pattern is sensitive to it
    citation_output = [x.lower() for x in citation_output]
    abrv_output = re.findall(abbrev_pattern, input_text) #regex based on capital so need to put before lower
    abrv_output = list(set([x.lower() for x in abrv_output])) #convert to lower for comparison 
    abrv_output = [j.replace(' ', '') for j in abrv_output] #remove space of the extracted abrv

    input_text = input_text.lower()

    email_output = re.findall(email_pattern, input_text)
    website_output = ["".join(x) for x in re.findall(website_pattern, input_text)]
    citation_output_2 = re.findall(citation_pattern_2, input_text)
    citation_output_2 = [x for x in citation_output_2 if len(x)!=4] #remove year in () from in-text citation
    
    mark_list = ['(', ')', '[', ']', ',', '.', ':', ';'] 

    #combine all regex output, except abbrv
    combined_output = list(set(email_output + website_output + citation_output + citation_output_2))

    updated_output = []

    #to remove in-text citation with last name of author only
    combined_citation = list(set(citation_output+citation_output_2))
    author_name = [k.split()[0] for k in combined_citation if ';' not in k]
    author_name_2 = [j.split()[0] for j in nltk.flatten([k.split(';') for k in combined_citation if ';' in k])]
    author_list = list(set(author_name+author_name_2))
    author_list

    #to make sure that the combined output is free from those marks and re-update to updated_output
    for item in combined_output:
        for mark in mark_list:
            if mark in item:
                item = item.replace(mark, '')
            else:
                continue
        updated_output.append(item)

    #to remove those regex output from the text, so that they're not involved during error detection
    #compare to both combined and updated to reduce the chance of miss captured words
    
    combined_output.sort(key=len, reverse=True) #prioritize longer string first, if not the short string will replace it
    updated_output.sort(key=len, reverse=True)

    #input_text = input_text.replace("’s", '') #different style of in-text citation
    apostrophe_result = re.findall("\w+\’s|\w+\'s", input_text)
    for i in apostrophe_result:
        if i in input_text:
            input_text = input_text.replace(i, '')

    for i in combined_output:
        if i in input_text:
            input_text = input_text.replace(i, '')

    for i in updated_output:
        if i in input_text:
            input_text = input_text.replace(i, '')

    for mark in mark_list:
        input_text = input_text.replace(mark, '')

    #check against the corpus
    input_words = input_text.split()
    for word in input_words:
        if len(word.lower())>1 and not word.isdigit() and word.lower() not in error_list and word.lower() not in abrv_output and word.lower() not in author_list:
            if word.lower() not in corpus_tokens:
                error_list.append(word)

    #remove word with dash which actually existed in corpus from error list            
    temp_list = []
    dash_mark = '-'
    for word in error_list:
        if dash_mark in word:
            split_word = word.split(dash_mark)
            for i in range(len(split_word)):
                if split_word[i] in corpus_tokens:
                    temp_list.append(word)
                    break
     
    for j in temp_list:
        error_list.remove(j)
    
    return error_list

"""## Minimum edit distance

### Lavenshtein distance
"""

def word_suggestion(error_list, corpus, transOP=False, suggestion_no=5): #default to Levenshtein if not specify
    
    total_dict = {}
    
    for word1 in error_list:
        ED_dict = {}
        ED_dict1 = {}
        sort_dict = {}
        for word2 in corpus:
            if abs(len(word1) - len(word2)) <= 2:
                distance = ED(word1, word2, transpositions=transOP)
                ED_dict[word2] = distance
                if distance <= 1:
                    ED_dict1[word2] = distance
        
        sort_dict['Top 5'] = heapq.nsmallest(suggestion_no, ED_dict, key=ED_dict.get)
        sort_dict['D1'] = heapq.nsmallest(suggestion_no, ED_dict1, key=ED_dict1.get)
        total_dict[word1] = sort_dict #use of nested dict to record error frequency if needed
         
    return total_dict

"""## Noisy channel model"""

def noisy_channel_model(suggestions, path=noisy_channel_path):

    final_channel = {}
    error_list = [k for k in suggestions.keys()]
    potential_candidates = [v['D1'] for v in suggestions.values()]

    for i in range(len(error_list)):
        channel = {}
        error = error_list[i]
        candidates = potential_candidates[i]
        if len(candidates)<2: continue
        else:
            for word in candidates:

                if len(error) == len(word):

                    dict1 = Counter(error)
                    dict2 = Counter(word)

                    if dict1 == dict2:
                        #both words have same alphabets, transposition
                        num = 0
                        while num < len(error):
                            #alphabets match
                            if error[num] == word[num]:
                                num += 1      
                            else:
                                edit = ''.join(reversed(word[num:num+2]))+'|'+word[num:num+2]
                                edit = edit.replace(" ", "")
                                break

                    else:
                        #substitution
                        num = 0
                        while num < len(error):
                            #alphabets match
                            if error[num] == word[num]:
                                num += 1      
                            else:
                                edit = error[num]+'|'+word[num]
                                edit = edit.replace(" ", "")
                                break

                elif len(error) < len(word):
                    #deletion
                    num = 0
                    while num < len(error):
                        #alphabets match
                        if error[num] == word[num]:
                            num += 1      
                        else:
                            edit = word[num-1]+'|'+word[num-1:num+1]
                            edit = edit.replace(" ", "")
                            break

                        #deletion at end of string
                        if num == len(error):
                            edit = word[num-1]+'|'+word[num-1:]
                            edit = edit.replace(" ", "")

                else:
                    #insertion
                    num = 0
                    while num < len(word):

                        #alphabets match
                        if error[num] == word[num]:
                            num += 1      
                        else:
                            edit = '>'+error[num]+'|>'
                            edit = edit.replace(" ", "")
                            break

                        #insertion at the end of string
                        if num == len(word):
                            edit = '>'+error[num]+'|>'


                channel[word] = edit
        final_channel[error] =channel
    
    #computation of probability
    df = pd.read_excel(path)
    final_dict = {}
    for k, v in final_channel.items():
        prob_dict = {}
        for k1, v1 in v.items():
            prob = df.loc[df['edit'] == v1, 'prob'].tolist()
            prob_dict[k1] = prob
        final_dict[k] = heapq.nlargest(len(v.items()), prob_dict, key=prob_dict.get)
    
    return final_dict

"""## Final suggestion"""

# Combine the output of word suggestion and noisy channel model
def combined_candidates(MED_cand, NC_cand):

    combined_cand = {}
    for k, v in MED_cand.items():
        if len(v['D1']) >= 2:
            combined_cand[k] = NC_cand[k]
            for candidate in v['Top 5']:
                if candidate not in NC_cand[k]:
                    combined_cand[k].append(candidate)
        else:
            combined_cand[k] = v['Top 5']

    ranking_list = [1,2,3,4,5]

    for k, v in combined_cand.items():
        ranked_cand = dict(zip(ranking_list, v))
        combined_cand[k] = ranked_cand
        
    return combined_cand

def display_suggestion(suggestion_list):
    for k, v in suggestion_list.items():
        try:
            print(f"{k}: {v['Top 5']}\n")
        except KeyError:
            print(f"{k}: {v}\n")
        except TypeError:
            print(f"{k}: {v}\n")

"""## Combined function"""

def non_word(input_text, corpus_tokens):
    
    #generate the error list
    error_list = error_detection(input_text, corpus_tokens)
    
    #generate the suggestions using edit distance
    dsuggestions = word_suggestion(error_list, corpus_tokens, transOP=True)

    #generate the suggestions using noisy channel model
    NC = noisy_channel_model(dsuggestions)
    
    #combine suggestions from two functions
    txt_correction = combined_candidates(dsuggestions, NC)
    
    #print out the errors with their suggestions
    nw_suggestion = display_suggestion(txt_correction)
    
    return nw_suggestion

"""# Real-word error

## Input text preprocessing
"""

# preprocessing for the input text for 
# -*- coding: utf-8 -*-

alphabets= "([A-Za-z])"
prefixes = "(Mr|St|Mrs|Ms|Dr)[.]"
suffixes = "(Inc|Ltd|Jr|Sr|Co)"
starters = "(Mr|Mrs|Ms|Dr|He\s|She\s|It\s|They\s|Their\s|Our\s|We\s|But\s|However\s|That\s|This\s|Wherever)"
acronyms = "([A-Z][.][A-Z][.](?:[A-Z][.])?)"
websites = "[.](com|net|org|io|gov)"

def split_into_sentences(text):
    text = " " + text + "  "
    text = text.replace("\n"," ")
    text = re.sub(prefixes,"\\1<prd>",text)
    text = re.sub(websites,"<prd>\\1",text)
    if "Ph.D" in text: text = text.replace("Ph.D.","Ph<prd>D<prd>")
    text = re.sub("\s" + alphabets + "[.] "," \\1<prd> ",text)
    text = re.sub(acronyms+" "+starters,"\\1<stop> \\2",text)
    text = re.sub(alphabets + "[.]" + alphabets + "[.]" + alphabets + "[.]","\\1<prd>\\2<prd>\\3<prd>",text)
    text = re.sub(alphabets + "[.]" + alphabets + "[.]","\\1<prd>\\2<prd>",text)
    text = re.sub(" "+suffixes+"[.] "+starters," \\1<stop> \\2",text)
    text = re.sub(" "+suffixes+"[.]"," \\1<prd>",text)
    text = re.sub(" " + alphabets + "[.]"," \\1<prd>",text)
    if "”" in text: text = text.replace(".”","”.")
    if "\"" in text: text = text.replace(".\"","\".")
    if "!" in text: text = text.replace("!\"","\"!")
    if "?" in text: text = text.replace("?\"","\"?")
    text = text.replace(".",".<stop>")
    text = text.replace("?","?<stop>")
    text = text.replace("!","!<stop>")
    text = text.replace("<prd>",".")
    sentences = text.split("<stop>")
    sentences = sentences[:-1]
    sentences = [s.strip() for s in sentences]
    return sentences

"""## Generate candidate set"""

# mbleven algorithm

# Constants
REPLACE = 'r'
INSERT = 'i'
DELETE = 'd'
TRANSPOSE = 't'

MATRIX = [
    ['id', 'di', 'rr'],
    ['dr', 'rd'],
    ['dd']
]

MATRIX_T = [
    ['id', 'di', 'rr', 'tt', 'tr', 'rt'],
    ['dr', 'rd', 'dt', 'td'],
    ['dd']
]


# Library API

def compare(str1, str2, transpose=False):
    len1, len2 = len(str1), len(str2)

    if len1 < len2:
        len1, len2 = len2, len1
        str1, str2 = str2, str1

    if len1 - len2 > 2:
        return -1

    if transpose:
        models = MATRIX_T[len1-len2]
    else:
        models = MATRIX[len1-len2]

    res = 3
    for model in models:
        cost = check_model(str1, str2, len1, len2, model)
        if cost < res:
            res = cost

    if res == 3:
        res = -1

    return res


def check_model(str1, str2, len1, len2, model):
    """Check if the model can transform str1 into str2"""

    idx1, idx2 = 0, 0
    cost, pad = 0, 0
    while (idx1 < len1) and (idx2 < len2):
        if str1[idx1] != str2[idx2 - pad]:
            cost += 1
            if 2 < cost:
                return cost

            option = model[cost-1]
            if option == DELETE:
                idx1 += 1
            elif option == INSERT:
                idx2 += 1
            elif option == REPLACE:
                idx1 += 1
                idx2 += 1
                pad = 0
            elif option == TRANSPOSE:
                if (idx2 + 1) < len2 and str1[idx1] == str2[idx2+1]:
                    idx1 += 1
                    idx2 += 1
                    pad = 1
                else:
                    return 3
        else:
            idx1 += 1
            idx2 += 1
            pad = 0

    return cost + (len1 - idx1) + (len2 - idx2)

#suggestions using mbleven algorithm

def word_suggestion2(word, corpus, suggestion_no=5): #default to Levenshtein if not specify
    
    suggestions = []
    ED_dict = {}
    for word2 in corpus:
        distance = compare(word, word2)
        
        #this is for mbleven
        if distance != -1:
            ED_dict[word2] = distance
            
    ED_dict = (dict(sorted(ED_dict.items(), key=lambda item:item[1])))
    ED_dict = dict(itertools.islice(ED_dict.items(), suggestion_no))
    suggestions = list(ED_dict.keys())
    
    return suggestions

"""## Noisy channel model"""

# suggestions using noisy channel model
def real_word(input_text):

    text = split_into_sentences(input_text)
    suggestions = {}

    for sentence in text:
        
        #tokenized the sentence and generate the bigrams
        words = nltk.word_tokenize(sentence)
        bigram_sentence = list(ngrams(words,2))
        count = 0
        
        for word in words[1:]: 
            
            if word.isalnum() and not word.isdigit():
                suggestion = ''

                #calcuate the probability of the original word
                first_bigram = bigram_sentence[count]
                second_bigram = bigram_sentence[count+1]
                
                first_bigram = tuple(item.lower() for item in first_bigram)
                second_bigram = tuple(item.lower() for item in second_bigram)
                
                max_prob = (bigram_count[first_bigram]+1)/len(bigram_corpus) * (bigram_count[second_bigram]+1)/len(bigram_corpus)

                #combine the variants of the word with the candidates
                variants = lexeme(word.lower())
                candidates = word_suggestion2(word.lower(), corpus_tokens_dup)
                candidates += variants
                candidates = list(set(candidates))

                #calculate the probablity of the other candidates
                for item in candidates:
                    
                    if item != word.lower():
                        first_bigram1 = (first_bigram[0], item)
                        second_bigram1 = (item, second_bigram[1])
                        
                        prob = (bigram_count[first_bigram1]+1)/len(bigram_corpus) * (bigram_count[second_bigram1]+1)/len(bigram_corpus)
 

                        if prob>max_prob:
                            max_prob = prob
                            suggestion = item                         

                #add the suggestions into a dictionary
                if suggestion != '':
                    suggestions[word] = [suggestion]
                    
            count += 1

            #ending criteria for the for-loop
            if count == (len(bigram_sentence)-2):
                    break
        
    ranking_list = [1]

    for k, v in suggestions.items():
        ranked_cand = dict(zip(ranking_list, v))
        suggestions[k] = ranked_cand

    return suggestions

"""## Capitalized error"""

def capitalized_error(input_text):
    
    capitalized_error = re.findall('(?<=[\.!?]\s)([a-z]+)', input_text)
    
    capitalized_suggestions = {}
    for error in capitalized_error:
        error_temp = '. '+ error.capitalize()
        error = '. ' + error
        capitalized_suggestions[error] = [error_temp]

    if len(re.findall('[a-z]', input_text[0])) !=0:
        first_error = re.findall('^([\w\-]+)', input_text)
        first_error = ''.join(first_error)
        capitalized_suggestions[first_error] = [first_error.capitalize()]
    
    ranking_list = [1]
    
    for k, v in capitalized_suggestions.items():
        ranked_cand = dict(zip(ranking_list, v))
        capitalized_suggestions[k] = ranked_cand
        
    return capitalized_suggestions

"""## Combined function"""

def real_words(input_text):
    
    #generate the suggestions for real-word errors
    suggestions = real_word(input_text)
    
    #generate the suggestions for lowercase letter errors
    capitalized_suggestions = capitalized_error(input_text)
    
    #combine suggestions from two functions
    suggestions.update(capitalized_suggestions)
    
    #print out the errors with their suggestions
    rw_suggestion = display_suggestion(suggestions)
    
    return rw_suggestion

"""# Appendix

## Input_text_1

###Without error (original)
Deep Convolutional Neural Network (CNN) is a special type of Neural Networks, which has shown exemplary performance on several competitions related to Computer Vision and Image Processing. Some of the exciting application areas of CNN include Image Classification and Segmentation, Object Detection, Video Processing, Natural Language Processing, and Speech Recognition. The powerful learning ability of deep CNN is primarily due to the use of multiple feature extraction stages that can automatically learn representations from the data. The availability of a large amount of data and improvement in the hardware technology has accelerated the research in CNNs, and recently interesting deep CNN architectures have been reported. Several inspiring ideas to bring advancements in CNNs have been explored, such as the use of different activation and loss functions, parameter optimization, regularization, and architectural innovations. However, the significant improvement in the representational capacity of the deep CNN is achieved through architectural innovations. Notably, the ideas of exploiting spatial and channel information, depth and width of architecture, and multi-path information processing have gained substantial attention. Similarly, the idea of using a block of layers as a structural unit is also gaining popularity. This survey thus focuses on the intrinsic taxonomy present in the recently reported deep CNN architectures and, consequently, classifies the recent innovations in CNN architectures into seven different categories. These seven categories are based on spatial exploitation, depth, multi-path, width, feature-map exploitation, channel boosting, and attention. Additionally, the elementary understanding of CNN components, current challenges, and applications of CNN are also provided.

###With errors
Deep Convaludional Neural Network (CNN) is a special type of Neural Networks, which has shown exemplary performance on several competitions related to Computer Vision and Image Processing. Some of the exciting application areas of CNN include Image Classification and Segmentation, Object Detection, Video Processing, Natural Language Processing, and Speech Recognition. The powerful learning ability of deep CNN is primarily due to the use of multipel feature extraction stages that can automatically learn representations from the dato. The availability of a large amount of data and improvement in the hardware technology has accelerated the research in CNNs, and recently interesting deep CNN architectures have been reported. Several inspiring ideas to bring advancements in CNNs have been explored, such as the use of different activadion and loss functions, parameter optimization, regulalaisation, and architechtural innovations. However, the significant improvement in the representational capacity of the deep CNN is achieved through architectural innovations. Notably, the ideas of exploiting spatial and channel information, depth and width of architecture, and multi-path information processing have gained substantial attention. Similarly, the idea of using a block of layers as a structural unit is also gaining popularity. This survey thus focuses on the intrinsic taxonomy present in the recently reported deep CNN architectures and, consequently, classifies the recent innovations in CNN architechtures into seven different categories. These seven categories are based on spatial exploitation, depth, multi-path, width, feature-map exploitation, channel boosting, and attention. Additionally, the elementary understanding of CNN components, current challenges, and applications of CNN are also provided.

## Input_text_2

###Without error
Machine Learning (ML) algorithms are known to learn the underlying relationship in data and thus make decisions without requiring explicit instructions. In literature, various exciting works have been reported to understand and/or emulate the human sensory responses such as speech and vision (Hubel and Wiesel 1962, 1968; Ojala et al. 1996; Chapelle 1998; Lowe 1999; Dalal and Triggs 2004; Bay et al. 2008; Heikkilä et al. 2009). In 1989, a new class of Neural Networks (NN), called Convolutional Neural Network (CNN) (LeCun et al. 1989) was reported, which has shown enormous potential in Machine Vision (MV) related tasks. CNNs are one of the best learning algorithms for understanding image content and have shown exemplary performance in image segmentation, classification, detection, and retrieval related tasks (Ciresan et al. 2012; Liu et al. 2019). The success of CNNs has captured attention beyond academia. In industry, companies such as Google, Microsoft, AT&T, NEC, and Facebook have developed active research groups for exploring new architectures of CNN (Deng et al. 2013). At present, most of the frontrunners of image processing and computer vision (CV) competitions are employing deep CNN based models. The attractive feature of CNN is its ability to exploit spatial or temporal correlation in data. The topology of CNN is divided into multiple learning stages composed of a combination of the convolutional layers, non-linear processing units, and subsampling layers (Jarrett et al. 2009). CNN is a feedforward multilayered hierarchical network, where each layer, using a bank of convolutional kernels, performs multiple transformations (LeCun et al. 2010). Convolution operation helps in the extraction of useful features from locally correlated data points. The output of the convolutional kernels is then assigned to the non-linear processing unit (activation function), which not only helps in learning abstractions but also embeds non-linearity in the feature space. This non-linearity generates different patterns of activations for different responses and thus facilitates in learning of semantic differences in images. The output of the non-linear activation function is usually followed by subsampling, which helps in summarizing the results and also makes the input invariant to geometrical distortions (Scherer et al. 2010; LeCun et al. 2010). CNN, with the automatic feature extraction ability, reduces the need for a separate feature extractor (Najafabadi et al. 2015). Thus, CNN without exhaustive processing can learn good internal representation from raw pixels. Notable attributes of CNN are hierarchical learning,  
Published in Artificial Intelligence Review, DOI: https://doi.org/10.1007/s10462-020-09825-63arXiv:1901.06032 [cs.CV] automatic feature extraction, multi-tasking, and weight sharing (Guo et al. 2016; Liu et al. 2017; Abbas et al. 2019). CNN first came to limelight through the work of LeCuN in 1989 for processing of grid-like topological data (images and time series data) (LeCun et al. 1989; Ian Goodfellow et al. 2017). The architectural design of CNN was inspired by Hubel and Wiesel’s work and thus mostly follows the basic structure of primate’s visual cortex (Hubel and Wiesel 1962, 1968). Different stages of the learning process in CNN show quite a resemblance to the primate’s ventral pathway of the visual cortex (V1-V2-V3-V4-IT/VTC) (Laskar et al. 2018).

###With errors
Machine Learning (ML) algorithms are known to learn the underlying relationship in data and thus make decisions without requiring explicit instructions. In literature, various exciting works have been reported to understand and/or emulate the human sensory responses such as speech and vision (Hubel and Wiesel 1962, 1968; Ojala et al. 1996; Chapelle 1998; Lowe 1999; Dalal and Triggs 2004; Bay et al. 2008; Heikkilä et al. 2009). In 1989, a new class of Neural Networks (NN), called Convolutional Neural Network (CNN) (LeCun et al. 1989) was reported, which has shown enormous potential in Machine Vision (MV) related tasks. CNNs are one of the best learning algorithms for understanding image content and have shown exemplary performance in image segmentation, classification, detection, and retrieval related tasks (Ciresan et al. 2012; Liu et al. 2019). The success of CNNs has captured attention beyond academa. In industry, companies such as Google, Microsoft, AT&T, NEC, and Facebook have developed active research groups for exploring new architectures of CNN (Deng et al. 2013). At present, most of the frontruners of image processing and computer visiin (CV)competitions are employing deep CNN based models. The attractive feature of CNN is its ability to exploit spatial or temporal correlation in data. The topology of CNN is divided into multiple learning stages composed of a combination of the convolutional layers, non-linear processing units, and subsampling layers (Jarrett et al. 2009). CNN is a feedforward multilayered hierarchical network, where each layer, using a bank of convolutional kernels, performs multiple tranformasions (LeCun et al. 2010). Convolution operation helps in the extraction of useful features from locally correlated data points. The output of the convolutional jetnels is then assigned to the non-linear processing unit (activation function), which not only helps in learning abstractions but also embeds non-linearity in the feature space. This non-linearity generates different patterns of activations for different responses and thus facilitates in learning of semantic differences in images. The output of the non-linear activation function is usually followed by subsampling, which helps in summarizing the results and also makes the input invariant to geometrical distortions (Scherer et al. 2010; LeCun et al. 2010). CNN, with the automatic feature extraction ability, reduces the need for a separate feature extractor (Najafabadi et al. 2015). Thus, CNN without exhaustive processing can learn good internal representation from raw pixels. Notable attributes of CNN are hierarchical learning,  
Published in Artificial Intelligence Review, DOI: https://doi.org/10.1007/s10462-020-09825-63arXiv:1901.06032 [cs.CV] automatic feature extraction, multi-tasking, and weight sharing (Guo et al. 2016; Liu et al. 2017; Abbas et al. 2019). CNN first came to limelight through the work of LeCuN in 1989 for processing of grid-like topological data (images and time series data) (LeCun et al. 1989; Ian Goodfellow et al. 2017). The architectural design of CNN was inspired by Hubel and Wiesel’s work and thus mostly follows the basic structure of primate’s visual cortex (Hubel and Wiesel 1962, 1968). Different stages of the learning process in CNN show quite a resemblance to the primate’s ventral pathway of the visual cortex (V1-V2-V3-V4-IT/VTC) (Laskar et al. 2018).

## Input_text_3

###Without error
Published in Artificial Intelligence Review, DOI: https://doi.org/10.1007/s10462-020-09825-647arXiv:1901.06032 [cs.CV]5.2CNN based natural language processing Natural Language Processing (NLP) converts language into a presentation that can easily be exploited by any computer. Although RNNs are very suitable for NLP applications, however, CNNs have also been utilized in NLP based applications such as language modeling, and analysis, etc. Especially, language modeling or sentence molding has taken a twist after the introduction of CNN as a new representation learning algorithm. Sentence modeling is performed to know semantics of the sentences and thus offer new and appealing applications according to customer requirements. Traditional methods of information retrieval analyze data, based on words or features, but ignore the core of the sentence. Kalchbrenner et al. (2014) proposed a dynamic CNN and dynamic k-max pooling during training. This approach finds the relations between words without taking into account any external source like parser or vocabulary (Kalchbrenner et al. 2014). In a similar way, Collobert and Weston (2008) proposed CNN based architecture that can perform various MLP related tasks at the same time as chunking, language modeling, recognizing name-entity, and role modeling related to semantics (Collobert and Weston 2008). In another work, Hu et al. proposed a generic CNN based architecture that performs matching between two sentences and thus can be applied to different languages (Hu et al. 2011).5.3CNN based object detection and segmentation. Object detection focuses on identifying different objects in images. Recently, R-CNN has been widely used for object detection. Ren et al. (2015) proposed an improvement over R-CNN named as fast R-CNN for object detection (Ren et al. 2015). In their work, a fully connected convolutional neural network is used to extract feature space that can simultaneously detect the boundary and score of objects located at different positions. Similarly, Dai et al. (2016) proposed region-based object detection using fully connected CNN (Dai et al. 2016). In Dai’s work, results are reported on the PASCAL VOC image dataset. Another object detection technique is reported by Gidaris et al. (Gidaris and Komodakis 2015), which is based on multi-region based deep CNN that helps to learn the semantic aware features. In Gidaris’s approach, objects are detected with high accuracy on PASCAL VOC 2007 and 2012 dataset. Recently, AE based CNN architectures have shown success in segmentation tasks. In this regard, various interesting CNN architectures have been reported for both semantic and instance-based segmentation tasks such as FCN,
Published in Artificial Intelligence Review, DOI: https://doi.org/10.1007/s10462-020-09825-648arXiv:1901.06032 [cs.CV] SegNet, Mask R-CNN, U-Net etc., (Ronneberger et al. 2015; Badrinarayanan et al. 2017; He et al. 2017; Zhang et al. 2018b).

###With errors
Published in Artificial Intelligence Review, DOI: https://doi.org/10.1007/s10462-020-09825-647arXiv:1901.06032 [cs.CV]5.2CNNbased natural language processing Natural Language Processing (NLP) converts language into a presentation thst can easily be exploited by any computer. Although RNNs are very suitable for NLP applications, however, CNNs have also been utilized in NLP based applications such as language modeling, and analysis, etc. Especially, language modalling or sentence molding has taken a twist after the introduction of CNN as a new representation learning algarithm. Sentence modeling is performed to know semantics of the sentences and thus offer new and appealing applications according to customr requirements. Traditional methods of information retrieval analyze data, based on words or features, but ignore the core of the sentence. Kalchbrenner et al. (2014) proposed a dynamic CNN and dynamic k-max pooling during training. This approach finds the relations between words without taking into account any external source like parser or vocabulary (Kalchbrenner et al. 2014). In a similar way, Collobert and Weston (2008) proposed CNN based architecture that can perform various MLP related tasks at the same time as chunking, language modelling, recognizing name-entity, and role modeling related to semantics (Collobert and Weston 2008). In another work, Hu et al. proposed a generic CNN based architecture that performs matching between two sentences and thus can be applied to different languages (Hu et al. 2011).5.3CNN based object detection and segmentayion. Object detection focuses on identifying different objects in images. Recently, R-CNN has been widely used for object detection. Ren et al. (2015) proposed an improvement over R-CNN named as fast R-CNN for object detection (Ren et al. 2015). In their work, a fully connected convolutional neural network is used to extract feature space that can simultaneously detect the bondari and score of objects located at different positions. Similarly, Dai et al. (2016) proposed region-based object detection using fully connected CNN (Dai et al. 2016). In Dai’s work, results are reported on the PASCAL VOC image dataset. Another object detection technique is reported by Gidaris et al. (Gidaris and Komodakis 2015), which is based on multi-region based deep CNN that helps to learn the semantic aware features. In Gidaris’s approach, objects are detected with high acuraxy on PASCAL VOC 2007 and 2012 dataset. Recently, AE based CNN architectures have shown success in segmentation tasks. In this regard, various interesting CNN architectures have been reported for both semantic and instance-based segmentayion tasks such as FCN, 
Published in Artificial Intelligence Review, DOI: https://doi.org/10.1007/s10462-020-09825-648arXiv:1901.06032 [cs.CV] SegNet, Mask R-CNN, U-Net etc., (Ronneberger et al. 2015; Badrinarayanan et al. 2017; He et al. 2017; Zhang et al. 2018b).

## Input_text_4

###Without error
Deep Convolutional Neural Network (CNN) is a special type of Neural Networks, which has shown exemplary performance on several competitions related to Computer Vision and Image Processing. Some of the exciting application areas of CNN include Image Classification and Segmentation, Object Detection, Video Processing, Natural Language Processing, and Speech Recognition. The powerful learning ability of deep CNN is primarily due to the use of multiple feature extraction stages that can automatically learn representations from the data. The availability of a large amount of data and improvement in the hardware technology has accelerated the research in CNNs, and recently interesting deep CNN architectures have been reported. Several inspiring ideas to bring advancements in CNNs have been explored, such as the use of different activation and loss functions, parameter optimization, regularization, and architectural innovations.

###With errors
Deep Convolutional Neuron Network (CNN) is an special typo of Neural Networks, which has shown exemplary performance on several competitions related to Computer Vision and Image Processing. some of the exciting application areas of CNN include Image Classification and Segmentation, Object Detection, Video Processing, Natural Language Processing, and Speech Recognition. The powerful learning ability of deep CNN is primarily due too the used of multiple feature extraction stages that can automatically learn representations from thew data. The availability of a large amount of data and improvement in the hardware technology has accelerated the research in CNNs, and recently interesting deep CNN architecture have been reported. several inspiring ideas to bring advancements in CNNs have been explored, such at the use of different activation and loss functions, parameter optimization, regularization, and architectural innovations.

## Input_text_5

###Without error
During training, Convolutional Neural Network (CNN) learns through backpropagation algorithm, by regulating the change in weights according to the target. Optimization of an objective function using a backpropagation algorithm is similar to the response-based learning of the human brain. The multi-layered, hierarchical structure of deep CNN, gives it the ability to extract low, mid, and high-level features. High-level features (more abstract features) are a combination of lower and mid-level features. The hierarchical feature extraction ability of CNN emulates the deep and layered learning process of the Neocortex in the human brain, which dynamically learns features from the raw data (Bengio 2009). The popularity of CNN is primarily due to its hierarchical feature extraction ability.

###With errors
During training, Convolutional Neural Network (CNN) learns though backpropagation algorithm, by regulating the change in weights according to the target. optimization of an objective function using a backpropagation algorithm is similar to the response based learning of the human brain. The multilayered, hierarchical structure of deep CNN, gives it the abiility to extract low, mid, and high-level features. high-level features (more abstract features) are a combination of lower and mid-level features. The hierarchical feature extraction ability off CNN emulates the deep and layered learning process of the Neocortex in the humane brain, which dynamically learns features from teh raw data (Bengio 2009). The popularity of CNN is primarily due to its hierarchical feature extraction ability.
"""